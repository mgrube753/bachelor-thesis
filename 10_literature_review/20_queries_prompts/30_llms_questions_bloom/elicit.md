## Prompt

What methods with Large Language Models are used to automatically generate exam questions for undergraduate computer science students, and how is the alignment with specific levels of Bloom's Taxonomy evaluated?

## Summary of top 4

Recent studies have explored the use of Large Language Models (LLMs) for automatically generating exam questions in various disciplines. Research has shown that LLMs can produce high-quality questions aligned with different levels of Bloom's Taxonomy for subjects like physics (Omopekunola & Kardanova, 2024), business process management (Rockembach & Thom, 2024), and social sciences (Scaria et al., 2024). These studies employed prompt engineering techniques to guide LLMs in generating questions at specific cognitive levels. The effectiveness of LLMs varied based on the prompting methods used, with instructional prompts yielding particularly good results (Omopekunola & Kardanova, 2024). Multiple LLMs, including GPT-3.5, GPT-4, LLaMA-2, and others, were evaluated for their question generation capabilities (Scaria et al., 2024; Rockembach & Thom, 2024). Additionally, research has investigated LLMs' performance in answering exam questions, comparing their responses to student submissions and assessing the efficacy of LLM detectors (Quille et al., 2024).

## Details

-   Mode: Find papers
-   No changes while searching
-   Sort: Most relevant

